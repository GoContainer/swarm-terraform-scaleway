---
- hosts: all
  user: root
  become: true
  vars:
    glusterfs_ppa_use: false
    gluster_mount_dir: /mnt/data
    gluster_brick_dir: /data
    gluster_brick_name: gluster

  tasks:

# Init Cluster Swarm
    - name: "[swarm_master] swarm init"
      command: docker swarm init
      when: inventory_hostname in groups['swarm_master']

    - name: "[swarm_master] get token"
      command: docker swarm join-token -q worker
      register: swarm_master_token_worker_tmp
      when: inventory_hostname in groups['swarm_master']

    - name: Define tmp var
      set_fact:
        swarm_master_ip="{% for host in groups['swarm_master'] %}{{ hostvars[host]['ansible_eth0']['ipv4']['address'] }}{% endfor %}"
        swarm_master_token_worker="{% for host in groups['swarm_master'] %}{{ hostvars[host]['swarm_master_token_worker_tmp'] }}{% endfor %}"

    - debug:
        msg: "{{ swarm_master_token_worker.stdout }}"

    - name: "[swarm_node] slave join master"
      command: docker swarm join --token {{ swarm_master_token_worker.stdout }} {{ swarm_master_ip }}:2377
      when: inventory_hostname in groups['swarm_node']

# Init Cluster GlusterFS
    - name: Define TPM private ip
      set_fact:
        gluster_servers_ips_tmp="{% for host in groups['swarm_glusterfs'] %}{{ hostvars[host]['ansible_eth0']['ipv4']['address'] }}|{% endfor %}"

    - name: Define glusterfs_create
      set_fact:
        glusterfs_create="{% for host in groups['swarm_glusterfs'] -%}{{ hostvars[host]['ansible_eth0']['ipv4']['address'] }}:{{ gluster_brick_dir }}{%- if not loop.last %} {% endif -%}{%- endfor %}"


    - name: Ensure Gluster brick and mount directories exist.
      file:
        path: "{{ item }}"
        state: directory
        owner: root
        group: root
        mode: 0775
      with_items:
        - "{{ gluster_brick_dir }}"
        - "{{ gluster_mount_dir }}"
      when: "inventory_hostname in groups['swarm_glusterfs']"

    # Gluster volume configuration.
    - name: Check if Gluster volumes already exist.
      shell: "gluster volume info"
      changed_when: false
      register: gluster_volume_info
      when: "inventory_hostname in groups['swarm_glusterfs']"

    - name: Connect to Gluster peers.
      shell: "gluster peer probe {{ item }}"
      register: gluster_peer_probe
      changed_when: "'already in peer list' not in gluster_peer_probe.stdout"
      failed_when: false
      with_items: "{{ gluster_servers_ips_tmp[:-1].split('|') }}"
      when: "inventory_hostname == groups.swarm_glusterfs[0] and 'Volume Name: gluster' not in gluster_volume_info.stdout"

    - name: Create Gluster volume.
      shell: "gluster volume create {{ gluster_brick_name }} replica 2 transport tcp {{ glusterfs_create }} force"
      register: gluster_volume_create
      changed_when: "'successful' in gluster_volume_create.stdout"
      when: "inventory_hostname == groups.swarm_glusterfs[0] and 'Volume Name: gluster' not in gluster_volume_info.stdout"

    - name: Ensure Gluster volume is started.
      shell: "gluster volume start {{ gluster_brick_name }}"
      register: gluster_volume_start
      changed_when: "'successful' in gluster_volume_start.stdout"
      when: "inventory_hostname == groups.swarm_glusterfs[0] and 'Volume Name: gluster' not in gluster_volume_info.stdout"

    - name: Ensure GlusterFS is installed.
      apt:
        name: "{{ item }}"
        state: latest
      with_items:
        - glusterfs-client
      when: "inventory_hostname == groups.swarm_master[0] or inventory_hostname == groups.swarm_node[0]"

    - name: Ensure the Gluster volume is mounted.
      mount:
        name: "{{ gluster_mount_dir }}"
        src: "{{ groups.swarm_glusterfs[0] }}:/{{ gluster_brick_name }}"
        fstype: glusterfs
        opts: "defaults,_netdev"
        state: mounted
      when: "inventory_hostname == groups.swarm_master[0] or inventory_hostname == groups.swarm_node[0]"

# Install Sweady
    - name: Clone project
      git:
        repo: https://github.com/GoContainer/Sweady.git
        dest: /tmp/sweady

    - name: Config for Prometheus
      copy:
        src: /tmp/sweady/docker-compose/monitoring/prometheus/prometheus.yml
        dest: /mnt/data/monitoring/prometheus/config/prometheus.yml
        owner: root
        group: root
        mode: 0755

    - name: Deploy monitoring stack
      command: docker stack deploy -c /tmp/sweady/docker-compose/monitoring/docker-compose.yml monitoring